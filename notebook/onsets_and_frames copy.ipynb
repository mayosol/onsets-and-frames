{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Unzip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchaudio\n",
    "import IPython.display as ipd\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import zipfile\n",
    "from glob import glob\n",
    "\n",
    "import pretty_midi\n",
    "pretty_midi.pretty_midi.MAX_TICK = 1e10\n",
    "\n",
    "torch.set_printoptions(sci_mode=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "maps_path = Path('/home/dasol/userdata/onsets-and-frames/maps')\n",
    "\n",
    "# UNZIP\n",
    "maps_piano_path = list(maps_path.rglob('*_2.zip'))\n",
    "# for path in maps_piano_path:\n",
    "#     zipfile.ZipFile(path).extractall(maps_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time2frame(time, sr=16000, hop_length=512):\n",
    "    return round((time * sr) / hop_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MAPSDataset:\n",
    "    def __init__(self, dir_path, split, sr=16000):\n",
    "        self.sr = sr\n",
    "        self.hop_length = 512\n",
    "        self.dir_path = list(dir_path.glob('./*/*/'))\n",
    "        self.frame_per_sec =  self.sr/self.hop_length\n",
    "\n",
    "        # split train, test set\n",
    "        train_folder = ['AkPnBcht', 'AkPnBsdf', 'AkPnCGdD', 'AkPnStgb', 'SptkBGAm', 'SptkBGCl', 'StbgTGd2']\n",
    "        test_folder = ['ENSTDkAm', 'ENSTDkCl']\n",
    "        self.target_folder = train_folder if split=='train' else test_folder\n",
    "\n",
    "        self._load_data()\n",
    "\n",
    "    def get_piano_roll(self, path):\n",
    "        # make label - total\n",
    "        midi = pretty_midi.PrettyMIDI(midi_file=path)\n",
    "        total = midi.get_piano_roll(fs=self.frame_per_sec, times=None, pedal_threshold=64)\n",
    "        total[total > 0] = 1 # remove velocity\n",
    "        total = total[21:109]\n",
    "        # make label - onset\n",
    "        onset = np.zeros_like(total)\n",
    "        for note in midi.instruments[0].notes:\n",
    "            onset[int(note.pitch) - 21, int(note.start * self.frame_per_sec)] = 1\n",
    "        pianoroll = np.stack([total, onset], axis=0)\n",
    "        return pianoroll\n",
    "\n",
    "    def _load_data(self):\n",
    "        # make lists of wav, midi paths\n",
    "        self.audio = []\n",
    "        self.roll = []\n",
    "        for path in self.dir_path:\n",
    "            folder = path.parent.name\n",
    "            wav_files = list(path.rglob('*.wav'))\n",
    "            missing_list = []\n",
    "\n",
    "            if folder in self.target_folder:\n",
    "                for file in wav_files:\n",
    "                    midi = file.with_suffix('.mid')\n",
    "                    if not midi.exists():\n",
    "                        missing_list.append(id)\n",
    "                        continue\n",
    "                    roll = self.get_piano_roll(str(midi))\n",
    "                    self.audio.append(file)\n",
    "                    self.roll.append(roll)\n",
    "        print(missing_list)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.audio)\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        audio, sr = torchaudio.load(self.audio[idx])\n",
    "        audio = torchaudio.functional.resample(audio, sr, self.sr)\n",
    "        roll = self.roll[idx]\n",
    "        start = random.randint(0, len(audio[0]) - (self.sr * 25) - 1)\n",
    "        end = start + (self.sr * 20)\n",
    "        sliced_audio = audio[:, start:end].mean(dim=0) # stereo to mono\n",
    "\n",
    "        start_roll = time2frame(start/self.sr)\n",
    "        end_roll = start_roll + int(20 * self.sr/512)\n",
    "        sliced_roll = roll[:, :, start_roll:end_roll]\n",
    "\n",
    "        return sliced_audio, sliced_roll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "trainset = MAPSDataset(maps_path, 'train')\n",
    "testset = MAPSDataset(maps_path, 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(trainset, batch_size=8, shuffle=True, num_workers=0)\n",
    "test_loader = DataLoader(testset, batch_size=10, num_workers=0)\n",
    "batch = next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([8, 320000]), torch.Size([8, 2, 88, 625]))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch[0].shape, batch[1].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Label끼리 잘 맞나 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_label(split: str, idx, slice: int):\n",
    "    if split == 'train':\n",
    "        label = trainset.roll[idx]\n",
    "    elif split == 'test':\n",
    "        label = testset.roll[idx]\n",
    "    plt.figure(figsize=(15, 7))\n",
    "    plt.imshow((label[0] + label[1])[:, :slice], aspect='auto', interpolation='nearest', origin='lower')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1080x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "check_label('train', 17, 300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### audio-label끼리 잘 맞나 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_audio, test_roll = trainset[77]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x11f366eb0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1080x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(15, 7))\n",
    "plt.imshow(test_roll[0], aspect='auto', interpolation='nearest', origin='lower')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 320000])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_audio = test_audio.view([1, -1])\n",
    "test_audio.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "torchaudio.save(filepath='/Users/idasol/Desktop/Visual_Studio_Projects/onsets_and_frames/audio_samples/sample8.wav', src= test_audio, sample_rate=16000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pitch2hz(pitch):\n",
    "    return 2 ** ((pitch-69) / 12) * 440"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 1, 352, 626])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mel_converter = torchaudio.transforms.MelSpectrogram(sample_rate=16000,\n",
    "                                                                  n_fft = 2048,\n",
    "                                                                  hop_length = 512,\n",
    "                                                                  f_min = 20,\n",
    "                                                                  f_max = 8000,\n",
    "                                                                  n_mels = 88 * 4,\n",
    "                                                            )\n",
    "\n",
    "test_mel = mel_converter(batch[0])\n",
    "test_mel = test_mel.unsqueeze(1)\n",
    "test_mel.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 256, 88, 626])\n",
      "torch.Size([8, 22528, 626])\n",
      "torch.Size([8, 626, 256])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 88, 626])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class OnsetModule(nn.Module):\n",
    "    def __init__(self, hidden_size=256):\n",
    "        super().__init__()\n",
    "\n",
    "        self.cnn = nn.Sequential(nn.Conv2d(1, hidden_size//4, kernel_size=(3, 3), padding=1),\n",
    "                                 nn.BatchNorm2d(hidden_size//4),\n",
    "                                 nn.MaxPool2d((2, 1)),\n",
    "                                 nn.ReLU(),\n",
    "                                 \n",
    "                                 nn.Conv2d(hidden_size//4, hidden_size//2, kernel_size=(3, 3), padding=1),\n",
    "                                 nn.BatchNorm2d(hidden_size//2),\n",
    "                                 nn.MaxPool2d((2, 1)),\n",
    "                                 nn.ReLU(),\n",
    "                                 \n",
    "                                 nn.Conv2d(hidden_size//2, hidden_size, kernel_size=(3, 3), padding=1),\n",
    "                                 nn.BatchNorm2d(hidden_size),\n",
    "                                 nn.ReLU(),)\n",
    "                                 \n",
    "        self.fc = nn.Linear(88 * hidden_size, hidden_size)\n",
    "        self.lstm = nn.LSTM(hidden_size, hidden_size, num_layers=3, bidirectional=True, batch_first=True)\n",
    "        self.projection = nn.Linear(hidden_size * 2, 88)\n",
    "\n",
    "    def forward(self, mel_spec):\n",
    "        conv_out = self.cnn(mel_spec)\n",
    "        print(conv_out.shape)\n",
    "        conv_out = conv_out.reshape(mel_spec.shape[0], -1, mel_spec.shape[-1])\n",
    "        print(conv_out.shape)\n",
    "        fc_out = self.fc(conv_out.permute(0, 2, 1))\n",
    "        print(fc_out.shape)\n",
    "        hidden_out, last_hidden = self.lstm(fc_out)\n",
    "        logit = self.projection(hidden_out)\n",
    "        prob = torch.sigmoid(logit)\n",
    "\n",
    "        return prob.permute(0, 2, 1) # pianoroll 형식으로 변환\n",
    "        \n",
    "\n",
    "model = OnsetModule()\n",
    "onset_out = model(test_mel)\n",
    "onset_out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 22528, 626])\n",
      "torch.Size([8, 626, 88])\n",
      "torch.Size([8, 626, 176])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 88, 626])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class FrameModule(nn.Module):\n",
    "    def __init__(self, hidden_size=256):\n",
    "        super().__init__()\n",
    "\n",
    "        self.cnn = nn.Sequential(nn.Conv2d(1, hidden_size//4, kernel_size=(3, 3), padding=1),\n",
    "                                 nn.BatchNorm2d(hidden_size//4),\n",
    "                                 nn.MaxPool2d((2, 1)),\n",
    "                                 nn.ReLU(),\n",
    "                                 \n",
    "                                 nn.Conv2d(hidden_size//4, hidden_size//2, kernel_size=(3, 3), padding=1),\n",
    "                                 nn.BatchNorm2d(hidden_size//2),\n",
    "                                 nn.MaxPool2d((2, 1)),\n",
    "                                 nn.ReLU(),\n",
    "                                 \n",
    "                                 nn.Conv2d(hidden_size//2, hidden_size, kernel_size=(3, 3), padding=1),\n",
    "                                 nn.BatchNorm2d(hidden_size),\n",
    "                                 nn.ReLU(),)\n",
    "                                 \n",
    "        self.fc = nn.Linear(88 * hidden_size, 88) \n",
    "        self.lstm = nn.LSTM(88 * 2, hidden_size, num_layers=3, bidirectional=True, batch_first=True)\n",
    "        self.projection = nn.Linear(hidden_size * 2, 88)\n",
    "\n",
    "    def forward(self, mel_spec, onset_out):\n",
    "        conv_out = self.cnn(mel_spec)\n",
    "        conv_out = conv_out.reshape(mel_spec.shape[0], -1, mel_spec.shape[-1])\n",
    "        print(conv_out.shape)\n",
    "        fc_out = self.fc(conv_out.permute(0, 2, 1))\n",
    "        print(fc_out.shape)\n",
    "        total_fc_out = torch.concat([onset_out.permute(0, 2, 1), fc_out], dim=2)\n",
    "        print(total_fc_out.shape)\n",
    "        hidden_out, last_hidden = self.lstm(total_fc_out)\n",
    "\n",
    "        logit = self.projection(hidden_out)\n",
    "        prob = torch.sigmoid(logit)\n",
    "        \n",
    "        return prob.permute(0, 2, 1) # pianoroll 형식으로 변환\n",
    "\n",
    "model = FrameModule()\n",
    "frame_out = model(test_mel, onset_out)\n",
    "frame_out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 256, 88, 626])\n",
      "torch.Size([8, 22528, 626])\n",
      "torch.Size([8, 626, 256])\n",
      "torch.Size([8, 22528, 626])\n",
      "torch.Size([8, 626, 88])\n",
      "torch.Size([8, 626, 176])\n"
     ]
    }
   ],
   "source": [
    "class OnsetAndFrameModel(nn.Module):\n",
    "    def __init__(self, hidden_size=256):\n",
    "        super().__init__()\n",
    "        self.mel_converter = torchaudio.transforms.MelSpectrogram(sample_rate=16000,\n",
    "                                                                  n_fft = 2048,\n",
    "                                                                  hop_length = 512,\n",
    "                                                                  f_min = 20,\n",
    "                                                                  f_max = 8000,\n",
    "                                                                  n_mels = 88 * 4,\n",
    "                                                            )\n",
    "        self.onset_module = OnsetModule()\n",
    "        self.frame_module = FrameModule()\n",
    "\n",
    "    def forward(self, x):\n",
    "        assert isinstance(x, torch.Tensor) and x.ndim == 2\n",
    "        mel_spec = self.mel_converter(x) # batch size x num mels x time\n",
    "        mel_spec = mel_spec.unsqueeze(1)\n",
    "\n",
    "        onset_out = self.onset_module(mel_spec)\n",
    "        frame_out = self.frame_module(mel_spec, onset_out)\n",
    "        return onset_out, frame_out\n",
    "\n",
    "model = OnsetAndFrameModel()\n",
    "onset_out, frame_out = model(batch[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLE_RATE = 16000\n",
    "HOP_LENGTH = SAMPLE_RATE * 32 // 1000\n",
    "MIN_MIDI = 21\n",
    "MAX_MIDI = 108\n",
    "\n",
    "N_MELS = 229\n",
    "MEL_FMIN = 30\n",
    "MEL_FMAX = SAMPLE_RATE // 2 \n",
    "WINDOW_LENGTH = 2048\n",
    "\n",
    "# DEFAULT_DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "cuda = torch.device('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvStack(nn.Module):\n",
    "    def __init__(self, hidden_size=256):\n",
    "        super().__init__()\n",
    "        self.cnn = nn.Sequential(nn.Conv2d(1, hidden_size//4, kernel_size=(3, 3), padding=1),\n",
    "                                 nn.BatchNorm2d(hidden_size//4),\n",
    "                                 nn.MaxPool2d((2, 1)),\n",
    "                                 nn.ReLU(),\n",
    "                                 \n",
    "                                 nn.Conv2d(hidden_size//4, hidden_size//2, kernel_size=(3, 3), padding=1),\n",
    "                                 nn.BatchNorm2d(hidden_size//2),\n",
    "                                 nn.MaxPool2d((2, 1)),\n",
    "                                 nn.ReLU(),\n",
    "                                 \n",
    "                                 nn.Conv2d(hidden_size//2, hidden_size, kernel_size=(3, 3), padding=1),\n",
    "                                 nn.BatchNorm2d(hidden_size),\n",
    "                                 nn.ReLU(),)\n",
    "                                 \n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(88 * hidden_size, hidden_size),\n",
    "            nn.Dropout(0.5)\n",
    "        )\n",
    "\n",
    "    def forward(self, mel_spec):\n",
    "        out = self.cnn(mel_spec)\n",
    "        out = out.reshape(mel_spec.shape[0], -1, mel_spec.shape[-1])\n",
    "        out = self.fc(out.permute(0, 2, 1))\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BiLSTM(nn.Module):\n",
    "    def __init__(self, input_features=256, hidden_size=128):\n",
    "        super().__init__()\n",
    "        self.rnn = nn.LSTM(input_features, hidden_size, num_layers=3, batch_first=True, bidirectional=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out, _ = self.rnn(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 1, 352, 626])\n",
      "torch.Size([8, 626, 256])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 626, 88])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mel_converter = torchaudio.transforms.MelSpectrogram(sample_rate=16000,\n",
    "                                                     n_fft = 2048,\n",
    "                                                     hop_length = 512,\n",
    "                                                     f_min = 20,\n",
    "                                                     f_max = 8000,\n",
    "                                                     n_mels = 88 * 4,)\n",
    "\n",
    "test_mel = mel_converter(batch[0])\n",
    "test_mel = test_mel.unsqueeze(1)\n",
    "print(test_mel.shape)\n",
    "\n",
    "conv = ConvStack()\n",
    "test = conv(test_mel)\n",
    "print(test.shape)\n",
    "\n",
    "lstm = BiLSTM()\n",
    "test2 = lstm(test)\n",
    "\n",
    "fc = nn.Linear(128*2, 88)\n",
    "test3 = fc(test2)\n",
    "sig = nn.Sigmoid()\n",
    "test4 = sig(test3)\n",
    "test4.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OnsetandFrameModel(nn.Module):\n",
    "    def __init__(self): \n",
    "        super().__init__()\n",
    "        \n",
    "        self.mel_converter = torchaudio.transforms.MelSpectrogram(sample_rate=16000,\n",
    "                                                                  n_fft = 2048,\n",
    "                                                                  hop_length = 512,\n",
    "                                                                  f_min = 20,\n",
    "                                                                  f_max = 8000,\n",
    "                                                                  n_mels = 88 * 4)\n",
    "\n",
    "        # sequence_model = lambda input_size, output_size: BiLSTM(input_size, output_size // 2)\n",
    "\n",
    "        self.onset_stack = nn.Sequential(\n",
    "            ConvStack(),\n",
    "            BiLSTM(),\n",
    "            nn.Linear(256, 88),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        self.frame_stack = nn.Sequential(\n",
    "            ConvStack(),\n",
    "            nn.Linear(256, 88),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        self.combined_stack = nn.Sequential(\n",
    "            BiLSTM(176, 128), # ?\n",
    "            nn.Linear(256, 88),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        mel_spec = self.mel_converter(x).unsqueeze(1)\n",
    "        onset_pred = self.onset_stack(mel_spec)\n",
    "        # offset_pred = self.offset_stack(mel_spec)\n",
    "        activation_pred = self.frame_stack(mel_spec)\n",
    "        combined_pred = torch.cat([onset_pred.detach(), activation_pred], dim=-1)\n",
    "        frame_pred = self.combined_stack(combined_pred)\n",
    "        # velocity_pred = self.velocity_stack(mel_spec)\n",
    "        return onset_pred.permute(0, 2, 1), activation_pred.permute(0, 2, 1), frame_pred.permute(0, 2, 1) ## ??\n",
    "        \n",
    "\n",
    "model = OnsetandFrameModel()\n",
    "onset_pred, activation_pred, frame_pred = model(batch[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 88, 626])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "onset_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([88, 625])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch[1][0, 1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.6936, dtype=torch.float64, grad_fn=<NegBackward0>),\n",
       " tensor(0.6932, dtype=torch.float64, grad_fn=<NegBackward0>))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_binary_cross_entropy_loss(pred, target, eps=1e-7):\n",
    "    return -(target * torch.log(pred+eps) + (1-target) * torch.log((1-pred)+eps)).mean()\n",
    "\n",
    "onset_loss = get_binary_cross_entropy_loss(onset_pred[..., :-1], batch[1][0, 1])\n",
    "frame_loss = get_binary_cross_entropy_loss(frame_pred[..., :-1], batch[1][0, 0])\n",
    "\n",
    "onset_loss, frame_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "model = OnsetandFrameModel()\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "num_epochs = 5\n",
    "loss_record = []\n",
    "test_record = []\n",
    "model.train()\n",
    "\n",
    "for epoch in  tqdm(range(num_epochs)):\n",
    "    for batch in tqdm(train_loader, leave=False):\n",
    "        audio, roll = batch\n",
    "        onset_pred, activation_pred, frame_pred = model(audio)\n",
    "        onset_loss = get_binary_cross_entropy_loss(onset_pred[..., :-1], roll[0, 1])\n",
    "        frame_loss = get_binary_cross_entropy_loss(frame_pred[..., :-1], roll[0, 0])\n",
    "        loss = onset_loss + frame_loss\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        loss_record.append(loss.item())\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        epoch_loss = 0\n",
    "        for batch in test_loader:\n",
    "            audio, roll = batch\n",
    "            onset_test_pred, activation_test_pred, frame_test_pred = model(audio)\n",
    "            onset_test_loss = get_binary_cross_entropy_loss(onset_pred[..., :-1], roll[0, 1])\n",
    "            frame_test_loss = get_binary_cross_entropy_loss(frame_pred[..., :-1], roll[0, 0])\n",
    "            test_loss = onset_test_loss + frame_test_loss\n",
    "            epoch_loss += test_loss.item()\n",
    "        test_record.append(epoch_loss / len(test_loader))\n",
    "    model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [5, 6, 7, 8, 9]\n",
    "y = []\n",
    "for num in range(len(x)):\n",
    "    convert = [(i, i) for i in range(num)]\n",
    "    for j in convert[1]:\n",
    "        for a in j :\n",
    "            y.append(a)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.8.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
